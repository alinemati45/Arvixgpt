{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Already Saved:In-context Autoencoder for Context Compression in a Large Language Model txt.\n",
      "- Already Saved:In-context Autoencoder for Context Compression in a Large Language Model pdf.\n",
      "- Already Saved:InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation txt.\n",
      "- Already Saved:InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation pdf.\n",
      "- Already Saved:mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs txt.\n",
      "- Already Saved:mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs pdf.\n",
      "- Already Saved:LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT txt.\n",
      "- Already Saved:LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT pdf.\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from io import BytesIO\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Function to sanitize a filename by removing invalid characters and replacing spaces with underscores.\n",
    "\n",
    "# link : http://lukasschwab.me/arxiv.py/index.html\n",
    "\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"\n",
    "    Sanitize a filename by removing invalid characters and replacing spaces with underscores.\n",
    "\n",
    "    :param filename: str, original filename\n",
    "    :return: str, sanitized filename\n",
    "    \"\"\"\n",
    "    # Characters that are not allowed in filenames\n",
    "    invalid_chars = set(r'\\/:*?\"<>|')\n",
    "\n",
    "    # Create a new string without invalid characters\n",
    "    sanitized_filename = \"\".join(c for c in filename if c not in invalid_chars)\n",
    "\n",
    "    # Replace spaces with underscores for readability and to avoid issues with command line operations\n",
    "    sanitized_filename = sanitized_filename.replace(\" \", \"_\")\n",
    "\n",
    "    # Return sanitized filename\n",
    "    return sanitized_filename\n",
    "\n",
    "\n",
    "def create_directory(directory):\n",
    "    \"\"\"\n",
    "    Create a directory if it does not exist.\n",
    "\n",
    "    :param directory: str, directory path\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Use 'exist_ok=True' to make this operation idempotent i.e., running it multiple times doesn't have different effects\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to download a PDF from a given URL and extract text from it.\n",
    "def download_article_pdf(result, url):\n",
    "    \"\"\"\n",
    "    Download a PDF from a given URL, check the updated date and extract text from it.\n",
    "\n",
    "    :param result: arxiv.Result, object containing information about an article\n",
    "    :param url: str, url to download the PDF from\n",
    "    :return: tuple(str, str), full_text and brief_text of the PDF along with its metadata\n",
    "    \"\"\"\n",
    "    updated_date = datetime.strptime(\n",
    "        str(result.updated), \"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "    # compare it with a specific date\n",
    "    # adjust this to the specific date you want\n",
    "    specific_date = datetime(2023, 1, 1, tzinfo=timezone.utc)\n",
    "\n",
    "    if updated_date <= specific_date:\n",
    "        # if the updated_date is on or before the specific date, don't continue the function\n",
    "        return None\n",
    "\n",
    "    response = requests.get(url)\n",
    "    # print(\"response: \", response)\n",
    "    # Initialize a PDF reader object with the content of the response\n",
    "    pdf = PdfReader(BytesIO(response.content))\n",
    "\n",
    "    # Build a string with metadata and content of the PDF document.\n",
    "    # Multiline string literals are used for clarity and conciseness.\n",
    "    full_text = f\"\"\"Title:\\t{result.title}\n",
    "Summary:\n",
    "{result.summary}\n",
    "\n",
    "PDF URL: \\t{result.pdf_url}\n",
    "Authors: \\t{result.authors}\n",
    "\n",
    "################################################################################################\n",
    "Published: \\t{result.published}\n",
    "Updated: \\t{result.updated}\n",
    "Entry ID: \\t{result.entry_id}\n",
    "Short ID: \\t{result.get_short_id()}\n",
    "\n",
    "###############################PDF Content Will Start From Here:###############################\n",
    "\"\"\"\n",
    "    brief_text = f\"\"\"Title:\\t{result.title}\n",
    "Summary:\n",
    "{result.summary}\n",
    "\n",
    "PDF URL:\\t{result.pdf_url}\n",
    "Authors:\\t{result.authors}\n",
    "\"\"\"\n",
    "    # Append the text of each page of the PDF to the full_text string\n",
    "    for page in pdf.pages:\n",
    "        full_text += page.extract_text()\n",
    "\n",
    "    # Return the full text of the PDF along with its metadata\n",
    "    return full_text, brief_text\n",
    "\n",
    "\n",
    "# Function to sanitize the article text by removing the 'References' section\n",
    "def sanitize_article_text(text):\n",
    "    \"\"\"\n",
    "    Sanitize the article text by removing the 'References' section.\n",
    "\n",
    "    :param text: str, original article text\n",
    "    :return: str, sanitized article text\n",
    "    \"\"\"\n",
    "    # Find the start of the 'References' section, if it exists\n",
    "    references_index = text.upper().find(\"REFERENCES\")\n",
    "\n",
    "    # If a 'References' section exists, remove everything from that point onwards\n",
    "    if references_index != -1:\n",
    "        text = text[:references_index]\n",
    "\n",
    "    # Return the sanitized article text\n",
    "    return text\n",
    "\n",
    "\n",
    "def save_article(save_path, text):\n",
    "    \"\"\"\n",
    "    Save the given text into a file at the specified path.\n",
    "\n",
    "    :param save_path: str, file path to save the article\n",
    "    :param text: str, text to be saved\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Open the file in write mode. If the file already exists, it will be overwritten.\n",
    "    # The 'encoding' argument is used to specify the encoding of the file.\n",
    "    # The 'errors' argument tells Python how to handle encoding errors.\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        # Write the text into the file\n",
    "        f.write(text)\n",
    "\n",
    "\n",
    "# Main function that searches for articles based on a keyword, downloads the PDFs,\n",
    "# extracts and sanitizes text from the PDFs, and saves the text and PDFs to specified directories\n",
    "\n",
    "def create_directory(directory):\n",
    "    \"\"\"\n",
    "    Create a directory if it does not exist.\n",
    "\n",
    "    :param directory: str, directory path\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def get_saved_filenames(directory):\n",
    "    \"\"\"\n",
    "    Get the filenames of the files already saved in the directory.\n",
    "\n",
    "    :param directory: str, directory path\n",
    "    :return: set, set of saved file names\n",
    "    \"\"\"\n",
    "    return set(os.listdir(directory))\n",
    "\n",
    "\n",
    "def setup_directories(txt_dir, pdf_dir, brief_dir):\n",
    "    \"\"\"\n",
    "    Create directories for saving text, PDFs and briefs if they do not exist.\n",
    "\n",
    "    :param txt_dir: str, directory path for text files\n",
    "    :param pdf_dir: str, directory path for pdf files\n",
    "    :param brief_dir: str, directory path for brief files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    create_directory(txt_dir)\n",
    "    create_directory(pdf_dir)\n",
    "    create_directory(brief_dir)\n",
    "\n",
    "\n",
    "def perform_search(keyword, n):\n",
    "    \"\"\"\n",
    "    Perform a search on arXiv based on the provided keyword.\n",
    "    Retrieve a maximum of n results sorted by the submission date in descending order.\n",
    "\n",
    "    :param keyword: str, keyword for search\n",
    "    :param n: int, number of maximum results\n",
    "    :return: arxiv.Search, object containing the search results\n",
    "    \"\"\"\n",
    "    return arxiv.Search(\n",
    "        query=keyword,\n",
    "        max_results=n,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "        sort_order=arxiv.SortOrder.Descending\n",
    "    )\n",
    "\n",
    "\n",
    "def print_if_saved(result, filenames_dict):\n",
    "    \"\"\"\n",
    "    Check if the files are already saved in the directories.\n",
    "    If so, print a message indicating that the article is already saved.\n",
    "\n",
    "    :param result: arxiv.Result, object containing information about an article\n",
    "    :param filenames_dict: dict, dictionary containing filenames and saved filenames\n",
    "    :return: bool, True if the files are already saved, False otherwise\n",
    "    \"\"\"\n",
    "    filename_text = filenames_dict['text']\n",
    "    filename_pdf = filenames_dict['pdf']\n",
    "    filename_brief = filenames_dict['brief']\n",
    "\n",
    "    saved_filenames_txt = filenames_dict['saved_txt']\n",
    "    saved_filenames_pdf = filenames_dict['saved_pdf']\n",
    "    saved_filenames_brief = filenames_dict['saved_brief']\n",
    "\n",
    "    if filename_text in saved_filenames_txt or filename_pdf in saved_filenames_pdf or filename_brief in saved_filenames_brief:\n",
    "        print(\n",
    "            f\"- Already Saved:{result.title} txt.\") if filename_text in saved_filenames_txt else None\n",
    "        print(\n",
    "            f\"- Already Saved:{result.title} pdf.\") if filename_pdf in saved_filenames_pdf else None\n",
    "        print(\n",
    "            f\"- Already Saved:{result.title} brief.\") if filename_brief in saved_filenames_brief else None\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_article_to_dict(result, brief_text, full_text):\n",
    "    \"\"\"Convert article information to a dictionary.\n",
    "\n",
    "    Args:\n",
    "        result: A single article information retrieved from search.\n",
    "        brief_text (str): Brief text information about the article.\n",
    "        full_text (str): Full text information about the article.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing key-value pairs of article information.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"Article_ID\": str(result.get_short_id()),\n",
    "        \"Title\": result.title, \"Summary\": str(result.summary),\n",
    "        \"PDF_URL\": result.pdf_url,\n",
    "        \"Authors\": \", \".join(str(author) for author in result.authors),\n",
    "        \"Published\": result.published,\n",
    "        \"Updated\": result.updated,\n",
    "        \"Brief_Text\": str(brief_text),\n",
    "        \"Full_Text\": str(full_text),\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def save_articles_to_csv(all_data):\n",
    "    \"\"\"Save articles information to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        all_data: A list of dictionaries, where each dictionary contains the info of one article.\n",
    "    \"\"\"\n",
    "    # Convert the list of data into a DataFrame\n",
    "    df_new = pd.DataFrame(all_data)\n",
    "    \n",
    "    # Initialize df_old as an empty DataFrame\n",
    "    df_old = pd.DataFrame()\n",
    "\n",
    "    # If the \"result.csv\" file exists, read its contents into df_old DataFrame\n",
    "    if os.path.exists(\"result.csv\"):\n",
    "        df_old = pd.read_csv(\"result.csv\")\n",
    "\n",
    "    # Concatenate the new dataframe (df_new) with the old dataframe (df_old), with new data on top\n",
    "    df_combined = pd.concat([df_new, df_old], ignore_index=True)\n",
    "\n",
    "    # Save the combined dataframe to CSV file\n",
    "    df_combined.to_csv(\"result.csv\", index=False, quoting=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sleep_time(i): # to avoid getting blocked IP by arXiv\n",
    "        if i == 0: # first time\n",
    "            print(\"We are about to start to retrieve articles from arXiv.\")\n",
    "            return True\n",
    "        else: # after first time\n",
    "            print(\"Sleeping for 5 seconds...to avoid getting blocked IP by arXiv.\")\n",
    "            time.sleep(5)\n",
    "            print(\"Awake!\")\n",
    "\n",
    "def main(keyword, maximum_number_articles_retrieve, save_directory_txt, save_directory_pdf, save_directory_brief):\n",
    "    \"\"\"\n",
    "    Main function to perform search, download articles, and save them.\n",
    "\n",
    "    :param keyword: str, keyword for search\n",
    "    :param n: int, number of maximum results\n",
    "    :param save_directory_txt: str, directory path for text files\n",
    "    :param save_directory_pdf: str, directory path for pdf files\n",
    "    :param save_directory_brief: str, directory path for brief files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Create directories for saving files if they do not exist\n",
    "    setup_directories(save_directory_txt, save_directory_pdf,\n",
    "                      save_directory_brief)\n",
    "\n",
    "    # Get the filenames of the files already saved in the directories\n",
    "    saved_filenames_txt = get_saved_filenames(save_directory_txt)\n",
    "    saved_filenames_pdf = get_saved_filenames(save_directory_pdf)\n",
    "    saved_filenames_brief = get_saved_filenames(save_directory_brief)\n",
    "\n",
    "    # Perform a search on arXiv based on the provided keyword\n",
    "    search = perform_search(keyword, maximum_number_articles_retrieve)\n",
    "\n",
    "\n",
    "    # For each article in the search results\n",
    "    for i, result in enumerate(search.results()):\n",
    "        # Initialize DataFrame with the necessary columns\n",
    "        # Sanitize the article's title to use it as a valid filename\n",
    "        filename = sanitize_filename(result.title)\n",
    "\n",
    "        # Get the updated date of the article and format it as \"YYYY_MM_DD\"\n",
    "        datetime_obj = datetime.strptime(\n",
    "            str(result.updated), \"%Y-%m-%d %H:%M:%S%z\").strftime(\"%Y_%m_%d\")\n",
    "\n",
    "        # Construct filenames for text, PDF, and brief formats\n",
    "        filename_text = datetime_obj + \"_\" + filename + \".txt\"\n",
    "        filename_pdf = datetime_obj + \"_\" + filename + \".pdf\"\n",
    "        filename_brief = datetime_obj + \"_\" + filename + \".brief.txt\"\n",
    "\n",
    "        # Construct a dictionary containing filenames and saved filenames\n",
    "        filenames_dict = {\n",
    "            'text': filename_text,\n",
    "            'pdf': filename_pdf,\n",
    "            'brief': filename_brief,\n",
    "            'saved_txt': saved_filenames_txt,\n",
    "            'saved_pdf': saved_filenames_pdf,\n",
    "            'saved_brief': saved_filenames_brief\n",
    "        }\n",
    "\n",
    "        # If the files are already saved, print a message and move to the next article\n",
    "        if print_if_saved(result, filenames_dict) == True: #  If the files are not already saved\n",
    "            # add one to i \n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        sleep_time(i)\n",
    "\n",
    "        # Download the PDF content of the article and extract the text\n",
    "        full_text, brief_text = download_article_pdf(result, result.pdf_url)\n",
    "\n",
    "        # Sanitize the article text by removing the 'References' section if present\n",
    "        text = sanitize_article_text(full_text)\n",
    "\n",
    "        # Define the path where the article text will be saved\n",
    "        save_path = os.path.join(save_directory_txt, filename_text)\n",
    "\n",
    "        # Save the article text to a file\n",
    "        save_article(save_path, text)\n",
    "\n",
    "        # Download the PDF version of the paper\n",
    "        paper = next(arxiv.Search(id_list=[result.get_short_id()]).results())\n",
    "        paper.download_pdf(dirpath=str(save_directory_pdf),\n",
    "                        filename=filename_pdf)\n",
    "\n",
    "        # Print a message to indicate that the article was saved successfully\n",
    "        print(f\"{result.title}. Link{result.pdf_url}. {datetime_obj} \")\n",
    "\n",
    "        # Save brief_text to a text file\n",
    "        save_path = os.path.join(save_directory_brief,\n",
    "                                \"brief_\" + filename_text)\n",
    "        save_article(save_path, brief_text)\n",
    "        # Download the PDF content of the article and extract the text\n",
    "        full_text, brief_text = download_article_pdf(result, result.pdf_url)\n",
    "        # Convert the article to a dictionary and append to the list\n",
    "        all_data.append(convert_article_to_dict(result, brief_text, full_text))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main function to get the keyword for the article search and define the directories where the articles will be saved.\n",
    "    \"\"\"\n",
    "    # Define the keyword for the article search\n",
    "    # Ask user to input the keyword for the article search if not provided \"large AND language AND models\"\n",
    "    # If no keyword is provided, prompt the user for a keyword\n",
    "    # keyword = \"large AND language AND models\"\n",
    "    keyword = None\n",
    "    if keyword is None:\n",
    "        keyword = input(\n",
    "            \"Enter the keyword for the article search: \") or \"large AND language AND models\"\n",
    "\n",
    "    # Define the maximum number of articles to retrieve, API's limit is 300,000\n",
    "    # ask user to input the maximum number of articles to retrieve if not provided\n",
    "\n",
    "    maximum_number_articles_retrieve = None\n",
    "    if maximum_number_articles_retrieve is None:\n",
    "        try:\n",
    "            maximum_number_articles_retrieve = int(input(\"Enter the maximum number of articles to retrieve (default is 4): \")) or 4\n",
    "        except ValueError:\n",
    "            maximum_number_articles_retrieve = 4\n",
    "\n",
    "        \n",
    "    # Define the directories where the articles will be saved\n",
    "    save_directory_pdf, save_directory_txt, save_directory_brief = (\n",
    "        \"save_directory_pdf\", \"save_directory_txt\", \"save_directory_brief\")\n",
    "\n",
    "    # Call the main function to perform the article search and save the articles\n",
    "    main(keyword, maximum_number_articles_retrieve, save_directory_txt,\n",
    "         save_directory_pdf, save_directory_brief)\n",
    "    # Call the function to save data to CSV\n",
    "    save_articles_to_csv(all_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Linkedin\\\\Post + latest Arxiv LLM papers'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='./logging_app/lapp.log', filemode='w', \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)  # Set level to INFO in the same basicConfig call\n",
    "# Creating an object \n",
    "logger=logging.getLogger() \n",
    "\n",
    "# Setting the threshold of logger to DEBUG \n",
    "logger.setLevel(logging.DEBUG) \n",
    "\n",
    "# Log messages\n",
    "logger.debug('This is a debug message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.info('This is an info message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.warning('This is a warning message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.error('This is an error message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.critical('This is a critical message')\n",
    "\n",
    "# at the end of your script\n",
    "logging.shutdown()\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Create and configure logger\n",
    "logging.basicConfig(filename=\"logfile.log\", \n",
    "                    format='%(asctime)s %(levelname)s: %(message)s', \n",
    "                    filemode='w')\n",
    "\n",
    "# Creating an object \n",
    "logger=logging.getLogger() \n",
    "\n",
    "# Setting the threshold of logger to DEBUG \n",
    "logger.setLevel(logging.DEBUG) \n",
    "\n",
    "# Log messages\n",
    "logger.debug('This is a debug message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.info('This is an info message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.warning('This is a warning message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.error('This is an error message')\n",
    "time.sleep(1)  # pause for 1 second\n",
    "logger.critical('This is a critical message')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
